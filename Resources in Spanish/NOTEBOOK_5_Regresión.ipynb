{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NOTEBOOK 5 - Regresión",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXOmuw5JYEcr"
      },
      "source": [
        "#NOTEBOOK 5: Regresión\n",
        "En este notebook, nos concentraremos en predecir la densidad del vino usando otro tipo de técnicas. Primero, encontraremos las correlaciones entre densidad y las otras variables. Después, usaremos la típica técnica de \"Regresión lineal univariada\" para predecir la densidad usando una única variable predictora. Por último, emplearemos varias técnicas de regresión multivariada de machine learning y las compararemos entre sí usando métricas de performance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHUTlSbeYPgG"
      },
      "source": [
        "## Tabla de contenidos\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2nZatEPEYfl"
      },
      "source": [
        "* [Correlaciones](#Correlaciones)\r\n",
        "* [Regresión Lineal](#Regresión_Lineal)\r\n",
        "* [Regresión Lineal múltiple](#Regresión_Lineal_múltiple)\r\n",
        "* [Escalado](#Escalado)\r\n",
        "* [LASSO](#Lasso)\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_gi1GrDDkPD"
      },
      "source": [
        "# Correlaciones\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtSisP67YGTv"
      },
      "source": [
        "Para ajustar los datos con una modelo de regresión lineal, es buena práctica emeplar variables que presenten una alta correlación con el objetivo (\"target\") Dos maneras de hacer esto es calculando los coeficientes de correlación, o bien usando métodos visuales.\n",
        "\n",
        "Predeciremos la densidad para vinos tintos (red whine), así que importaremos los datos y luego analizaremos el dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7Ul9Zw8gbhz"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df=pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\", delimiter=\";\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azEql8f3qLt7"
      },
      "source": [
        "Podemos aplicar el método **corr** de Pandas para calcular las correlaciones entre pares para las columnas del dataset [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html 'pandas.DataFrame.corr')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "992t5q-ZDlID"
      },
      "source": [
        "correlations = df.corr()['density'].drop(['quality', 'density'])\n",
        "print(correlations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ruj7tKOXq9vQ"
      },
      "source": [
        "Otra forma de hacerlo, es realizar un gráfico interactivo con ipywidgets que nos permita visualizar qué tan diferentes son las correlaciones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-j572WHf6BX"
      },
      "source": [
        "import ipywidgets as widgets\r\n",
        "from IPython.display import display\r\n",
        "\r\n",
        "Predictor_Var = list(df.columns)\r\n",
        "\r\n",
        "def CorrVis(Predictor_Var):\r\n",
        "  plt.scatter(df['density'],df[Predictor_Var])\r\n",
        "  plt.xlabel('Density')\r\n",
        "  plt.ylabel(Predictor_Var)\r\n",
        "  print('Corr Coef = ', np.corrcoef(df['density'],df[Predictor_Var])[0,1])\r\n",
        "\r\n",
        "widgets.interactive(CorrVis, Predictor_Var = list(df.columns))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hv6vU1vtaZi5"
      },
      "source": [
        "#Regresión Lineal\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s66Io-mlDxH"
      },
      "source": [
        "En esta sección, vamos a realizar una regresión lineal usando \"alcohol\" como variable predictora ($x_i$) y densidad como objetivo ($y_i$), de acuerdo al modelo:\r\n",
        "\r\n",
        "$\r\n",
        "y_i = β_1 x_i + β_0\r\n",
        "$\r\n",
        "\r\n",
        "Separaremos los datos en un set de entrenamiento un set de testeo, lo cual se utiliza habitualmente en métodos de machine learning para la validación del modelo creado. Para más información visita la [documentación](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html 'sklearn.model_selection.train_test_split')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P8Bv-Amgo-S"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df[['alcohol']]\n",
        "y = df['density']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UsXDn1z3A2z"
      },
      "source": [
        "Vamos a importar la librería para realizar regresión lineal y definir cual es la variable predictora y cual la variable objetivo. Para más información, visita la [documentación](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html 'sklearn.linear_model.LinearRegression')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOC2tM96hJ2H"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "linear_regression = LinearRegression()\n",
        "linear_regression.fit(X = X_train, y = y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaxEYz2UvGtA"
      },
      "source": [
        "Imprimamos en la pantalla los parametros de la regresión lineal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz7NbeFmkTIo"
      },
      "source": [
        "print('β1 = ' + str(linear_regression.coef_) + ', β0 = ' + str(linear_regression.intercept_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqvRQzH4vZP6"
      },
      "source": [
        "Podemos cuantificar qué tan bueno es el ajuste usando $R^2$. Para más información, visita la [documentación](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics 'Regression metrics') \n",
        "\n",
        "$\n",
        "R^2 =1- \\frac{\\sum{ (y_i-\\hat{y})^2}}{\\sum{(y_i-\\overline{y})^2}}\n",
        "$\n",
        "\n",
        "Los ajustes usualemnte son mejores en los sets de entrenamiento que en los sets de testeo, en este caso, encontramos que el set de entrenamiento tiene algunos outliers que hacen que el ajuste para set de entrenamiento no sea tan bueno."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXhPWi6HlGDN"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "y_pred_test = linear_regression.predict(X_test)\n",
        "y_pred_train = linear_regression.predict(X_train)\n",
        "\n",
        "print('R2 train = ', r2_score(y_train, y_pred_train))\n",
        "print('R2 test = ', r2_score(y_test, y_pred_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLKkU8jlx_Xq"
      },
      "source": [
        "Una manera de visualizar qué tan bueno es el ajuste es graficar el valor predicho contra el valor real."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud_geEexPGAJ"
      },
      "source": [
        "plt.scatter(y_train,y_pred_train, label='Training Set')\r\n",
        "plt.scatter(y_test,y_pred_test, label='Test Set')\r\n",
        "plt.xlabel('Real')\r\n",
        "plt.ylabel('Predicted')\r\n",
        "plt.legend()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiMNw1AVakPQ"
      },
      "source": [
        "#Regresión Lineal Múltiple\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TQCrv3pMX9q"
      },
      "source": [
        "Regresión Lineal Múltiple (MLR) es una generalización de la clásica regresión lineal. MLR modela una regresión lineal entre la respuesta del objetivo y múltiples variable explicativas.\r\n",
        "​\t  \r\n",
        "$y_i =β_0​\t +β_1\t x_{i1}​\t + β_2 x_{i2}​\t +...+ β_p​\t x_{ip}​\r\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkOjtIPhhnfi"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop(['quality', 'density'], axis=1)\n",
        "y = df['density']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbN7my680Zub"
      },
      "source": [
        "Como MLR es una generalización, la librería de **Scikit Learn** usa la misma función que usamos antes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htucZvq3aHLC"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "multiple_linear_regression = LinearRegression()\n",
        "multiple_linear_regression.fit(X = X_train, y = y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjI4z6TK08AF"
      },
      "source": [
        "Aumentar el número de variables predictoras lleva a un mejor ajuste del objetivo, lo cual genera que el valor de $R^2$ incremente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V0C9Abnj6j8"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "pred_train_lr = multiple_linear_regression.predict(X_train)\n",
        "pred_test_lr = multiple_linear_regression.predict(X_test)\n",
        "\n",
        "print('R2 training = ', r2_score(y_train, pred_train_lr))\n",
        "print('R2 test = ', r2_score(y_test, pred_test_lr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjUPKxLk7dcE"
      },
      "source": [
        "Otra métrica útil es $RSME$ y tiene la ventaja de que puede ser usada para modelos no lineales. Para más información, por favor visita la [documentación](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics 'Regression metrics')\n",
        "\n",
        "$\n",
        "RMSE =\\sqrt{ \\frac{1}{n} \\sum{(y_i - \\hat{y})^2}}\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlLaztfF7dpC"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test,pred_test_lr))\n",
        "print('RSME test= ', rmse_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r73gPeLh4xWe"
      },
      "source": [
        "Otra vez, podemos usar un gráfico para comparar el set de entrenamiento y el de testeo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z2CE37nQekx"
      },
      "source": [
        "plt.scatter(y_train,pred_train_lr, label='Training Set')\r\n",
        "plt.scatter(y_test,pred_test_lr, label='Test Set')\r\n",
        "\r\n",
        "plt.xlabel('Real')\r\n",
        "plt.ylabel('Predicted')\r\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv-53KG35LEP"
      },
      "source": [
        "Analicemos los coeficientes de MLR y prestemos antención a su magnitud. Parece difícil poder concluir algo que acerca de su importancia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt3E5fKFEXXq"
      },
      "source": [
        "coeffecients = pd.DataFrame(multiple_linear_regression.coef_,X.columns.tolist())\n",
        "coeffecients.columns = ['Coeficiente'] \n",
        "print(coeffecients)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NmV3868IOuw"
      },
      "source": [
        "coeffecients.plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiCPdPpQ3XsM"
      },
      "source": [
        "#Estandarización\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MUqgQCK-Gxf"
      },
      "source": [
        "La estandarización es un método para transformas las diferentes variables predictoras en rangos comparable. Debido a que es un set de datos estandarizados (autoescalados), un coeficiente más alto indica que es una variable predictora que tiene mayor importancia para predecir el objetivo\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6cbJJpw3b1j"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop(['quality', 'density'], axis=1)\n",
        "y = df['density']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiqx1u3qH3rk"
      },
      "source": [
        "Estandarizar después de dividir el dataset es una forma de evitar sesgo o error sistemático.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzuKE6ocGPZ7"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "scaler = preprocessing.StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCSQhJcB3-lw"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "multiple_linear_regression = LinearRegression()\n",
        "multiple_linear_regression.fit(X = X_train, y = y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V531KaMB3_n8"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "y_pred = multiple_linear_regression.predict(X_test)\n",
        "\n",
        "rmse_MLR = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print('R2 test = ', r2)\n",
        "print('RSME test = ', rmse_MLR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95kTjGWwIJGL"
      },
      "source": [
        "A medida que la data va siendo estandarizada, podemos analizar los coeficientes y determinar cuales son finalmente las variables predictores más importantes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDXazK3tGbv5"
      },
      "source": [
        "coeffecients = pd.DataFrame(multiple_linear_regression.coef_,X.columns.tolist())\n",
        "coeffecients.columns = ['Coeffecient'] \n",
        "print(coeffecients)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIL2FZbPIeC9"
      },
      "source": [
        "Encontramos que algunas variables no son tan importantes para generar el modelo de regresión. Vale la pena mencionar que usando solamente el \"alcohol\", \"residual sugar\", \"fixed acidity\", y el \"pH\", se podría hacer un mejor modelo ya que las otras variables no afectan notablemente la predicción e introducen ruido al modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6I1jIqCIHokY"
      },
      "source": [
        "coeffecients.plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz-ZShKVpwTh"
      },
      "source": [
        "#LASSO\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuoVstqnRQtR"
      },
      "source": [
        "\"Least Absolute Shrinkage and Selection Operator\" - \"Operador de Selección y Menor Encogimiento Absoluto\" (LASSO) es un método de regresión lineal que produce una selección de variables y regularización para mejorar la precisión de la predicción y generar un modelo más pequeño. Este método usa una función de \"costo\", con una constante alfa que define el grado de penalización.\n",
        "\n",
        "$\n",
        "LASSO_{CostFunction}=\\sum_{i=1}^M (y_i-\\hat{y_i})^2=\\sum_{i=1}^M (y_i-\\sum_{j=0}^p w_j \\times x_{ij})^2 + \\alpha\\sum_{j=0}^p |w_j| \\\\\n",
        "For \\; some \\; t \\, > \\, 0, \\, \\sum_{j=0}^p |w_j|<t\n",
        "$\n",
        "\n",
        "**Scikit Learn** implementa LASSO en la función **sklearn.linear_model.Lasso**- Para más información, visita la [documentación](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html 'sklearn.linear_model.Lasso')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnacIgj_nsVA"
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "lasso_regression = Lasso(alpha=0.001)\n",
        "lasso_regression.fit(X = X_train, y = y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUx82TcKOi2-"
      },
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "y_pred = lasso_regression.predict(X_test)\n",
        "\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print('R2 test = ', r2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLCUzPHp7u4p"
      },
      "source": [
        "Analizamos si usando LASSO tenemos un modelo más pequeño donde algunos de los coeficientes son cero."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ngK_8SKOssC",
        "outputId": "fe2c24a2-27b3-4d4a-833b-a49e19d667de"
      },
      "source": [
        "coeffecients = pd.DataFrame(lasso_regression.coef_,X.columns.tolist())\n",
        "coeffecients.columns = ['Coeffecient'] \n",
        "print(coeffecients)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                      Coeffecient\n",
            "fixed acidity            0.000518\n",
            "volatile acidity         0.000000\n",
            "citric acid              0.000000\n",
            "residual sugar           0.001855\n",
            "chlorides                0.000027\n",
            "free sulfur dioxide     -0.000000\n",
            "total sulfur dioxide     0.000090\n",
            "pH                       0.000345\n",
            "sulphates                0.000096\n",
            "alcohol                 -0.001337\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGLwRUjqPJIL"
      },
      "source": [
        "coeffecients.plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trrowEbG8G5F"
      },
      "source": [
        "Analizaremos como el RSME de los sets de entrenamiento y testeo cambian para diferentes valores de alfa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LidWrIf5sAtj"
      },
      "source": [
        "alphas=np.logspace(-10,3,endpoint=True,num=100,base=10)\r\n",
        "RMSE=[]\r\n",
        "RMSE_p=[]\r\n",
        "for x in (alphas):\r\n",
        "    #print(x)\r\n",
        "    model_lasso = Lasso(x)\r\n",
        "    model_lasso.fit(X_train, y_train)\r\n",
        "    pred_test_lasso= model_lasso.predict(X_test)\r\n",
        "    pred_train_lasso=model_lasso.predict(X_train)\r\n",
        "    RMSE_p.append(np.sqrt(mean_squared_error(y_test,pred_test_lasso)))\r\n",
        "    RMSE.append(np.sqrt(mean_squared_error(y_train,pred_train_lasso)))\r\n",
        "    \r\n",
        "\r\n",
        "plt.plot(alphas,RMSE, label='Training Set')\r\n",
        "plt.plot(alphas,RMSE_p, label='Test Set')\r\n",
        "plt.plot(alphas,len(alphas)*[rmse_MLR], label='MLR')\r\n",
        "plt.xscale(\"log\")\r\n",
        "plt.xlabel('alpha')\r\n",
        "plt.ylabel('RMSE')\r\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOigfW4kRBjM"
      },
      "source": [
        "Podemos ahora hacer un gráfico avanzado usando ipywidgets que nos permita cambiar los coeficientes de acuerdo a los valores de alfa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-l5rsYRPLF9"
      },
      "source": [
        "import ipywidgets as widgets\n",
        "\n",
        "from IPython.display import display\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "data_lasso = df.copy()\n",
        "data_lasso = data_lasso.drop(labels = ['quality','density'],axis = 1)\n",
        "features = data_lasso.columns.tolist()\n",
        "data_lasso = preprocessing.StandardScaler().fit_transform(data_lasso)\n",
        "y_lasso = df['density']\n",
        "\n",
        "def Lassovis(alpha):\n",
        "    lasso_regression = Lasso((alpha))\n",
        "    lasso_regression.fit(X = data_lasso, y = y_lasso)\n",
        "        \n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.subplot(211)\n",
        "    pred_test_lasso=lasso_regression.predict(X_test)\n",
        "    plt.scatter(y_test,pred_test_lasso)\n",
        "    plt.xlabel('y_test')\n",
        "    plt.ylabel('pred_test_lasso')\n",
        "\n",
        "    plt.subplot(212)\n",
        "    plt.bar(features,lasso_regression.coef_)\n",
        "    plt.xticks(rotation=90)\n",
        "\n",
        "\n",
        "widgets.interact(Lassovis,alpha=widgets.FloatLogSlider(name='Alpha', base=10, min=-5, max=-2, step=0.25, value=0.001));"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}